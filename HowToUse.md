
太好了，这个需求非常适合做成“新手照着做就能跑通”的流程。  
下面我给你一份 **Python 初学者版 CosyVoice 使用指南（macOS）**，按步骤执行即可。

---

## 1. 你最终会得到什么

完成后你可以做到：

1. 用你的一段录音（`m4a/wav/mp3` 都行）做音色克隆  
2. 输入任意中文或英文文本  
3. 生成带你音色的语音文件（`.wav`）

---

## 2. 先理解 3 个关键输入（非常重要）

每次合成都需要这三项：

1. `--prompt_wav`：你的参考录音（比如 `my_voice.m4a`）  
2. `--prompt_text`：这段录音**真实说过的原文**（必须尽量一致）  
3. `--text`：你想让模型读的新文本（可中文/英文）

---

## 3. 环境准备（一步步复制）

> 下面以你的目录为例：`/Users/daltonllin/CodeBuddy/20260228160444`

### 3.1 进入项目目录

```bash
cd /Users/daltonllin/CodeBuddy/20260228160444/CosyVoice
```

### 3.2 创建并激活 Python 虚拟环境（Python 3.10）

```bash
python3.10 -m venv /Users/daltonllin/CodeBuddy/20260228160444/.venv-cosyvoice310
source /Users/daltonllin/CodeBuddy/20260228160444/.venv-cosyvoice310/bin/activate
```

激活成功后，命令行前面会出现 `(.venv-cosyvoice310)`。

### 3.3 安装依赖

先升级基础工具：

```bash
pip install --upgrade pip setuptools wheel
pip install "setuptools<81"
```

再安装 CosyVoice 依赖（macOS 稳定做法）：

```bash
awk '!/openai-whisper/' requirements.txt > /tmp/req_no_whisper.txt
pip install -r /tmp/req_no_whisper.txt
pip install openai-whisper==20231117 --no-build-isolation
rm -f /tmp/req_no_whisper.txt
```

### 3.4 初始化子模块（必须）

```bash
git submodule update --init --recursive
```

### 3.5 确认 `ffmpeg` 可用（用于自动处理 m4a）

```bash
ffmpeg -version
```

---

## 4. 下载模型（第一次需要，时间较长）

在已激活虚拟环境下执行：

```bash
python -c "from modelscope import snapshot_download; snapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')"
```

说明：
- 首次下载会比较慢，属于正常现象  
- 下载完成后目录会有：`pretrained_models/CosyVoice-300M`

---

## 5. 直接使用（命令行方式，最适合新手）

你当前项目里已经有 `clone_tts.py`，并支持 `m4a` 自动转换，无需手动转格式。

### 5.1 中文合成示例

```bash
python clone_tts.py --prompt_wav "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/my_voice.m4a" --prompt_text "这里写你的录音中真实说过的一句话" --text "你好，这是一段克隆后的中文语音。" --output "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/outputs/my_zh.wav"
```

### 5.2 英文合成示例

```bash
python clone_tts.py --prompt_wav "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/my_voice.m4a" --prompt_text "这里写你的录音中真实说过的一句话" --text "Hello, this is an English sentence generated by my cloned voice." --output "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/outputs/my_en.wav"
```

### 5.3 批量合成（`texts_example.txt` 的用途）

当你要一次性生成很多条音频时，用 `batch_clone_tts.py` + `texts_example.txt`。

`texts_example.txt` 的规则：
- 一行就是一条要合成的文本
- 支持中文和英文混合
- 空行会自动忽略
- 以 `#` 开头的行会当作注释忽略

示例文件（可直接改）：
`/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/texts_example.txt`

运行命令：

```bash
python batch_clone_tts.py \
  --prompt_wav "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/my_voice.m4a" \
  --prompt_text "你即将踏入一座由人工智能驱动的小镇" \
  --input_txt "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/texts_example.txt" \
  --output_dir "/Users/daltonllin/CodeBuddy/20260228160444/CosyVoice/outputs/my_batch" \
  --prefix "myvoice"
```

输出结果示例：
- `outputs/my_batch/myvoice_001.wav`
- `outputs/my_batch/myvoice_002.wav`
- `outputs/my_batch/myvoice_003.wav`

---

## 6. Python 基本调用方法（代码方式）

如果你以后想在 Python 程序里直接调用，基本写法是：

```python
import torchaudio
import sys
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import AutoModel

cosyvoice = AutoModel(model_dir='pretrained_models/CosyVoice-300M')

for i, item in enumerate(cosyvoice.inference_zero_shot(
    "你好，这是一段测试文本。",
    "这里放参考音频对应的原文",
    "my_voice.wav",   # 参考音频路径
    stream=False
)):
    torchaudio.save(f"output_{i}.wav", item["tts_speech"], cosyvoice.sample_rate)
```

---

## 7. 新手最常见报错与解决

### 报错 1：`Prompt audio not found`
原因：路径写错（比如用了占位符 `/你的路径/...`）。  
解决：用真实绝对路径，并加引号。

---

### 报错 2：命令换行后参数丢失
原因：`\` 后面多了空格。  
解决：要么用我给你的**单行命令**，要么保证反斜杠是每行最后一个字符。

---

### 报错 3：效果不像你声音
常见原因：
- `prompt_text` 与录音不一致
- 录音噪音大、太短（<3秒）或混响重
- 语速太快、咬字不清

建议：
- 录音 5~15 秒，安静环境，普通说话音量  
- `prompt_text` 一字不差  
- 先短句测试，再生成长文本

---

## 8. 使用建议（提升成功率）

1. 参考音频建议单人、干净、无背景音乐  
2. 先跑短文本确认音色，再跑长段落  
3. 中文英文都支持，但英文自然度受参考音色和文本复杂度影响  
4. 仅在你有合法授权时克隆他人声音

